<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Weihang RanÂÜâ Áª¥Ëà™</title>
  <style>
        .container {
            width: 100%;
            display: flex;
            justify-content: space-between;
        }

        .left-align {
            text-align: left;
        }

        .right-align {
            text-align: right;
        }
    </style>

  <meta name="author" content="Weihang Ran">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon"
    href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Weihang Ran ÂÜâ Áª¥Ëà™</name>
                  </p>
                  <p>My name is Weihang Ran (ÂÜâ„ÄÄÁ∂≠Ëà™„ÄÄ„Çº„É≥„ÄÄ„Ç§„Ç≥„Ç¶). I am currently a 1st year Doctoral student from <a
                      href="https://oscarslab.github.io/">OSCARS Lab</a> in the Graduate School of Information Science and 
		      Technology, the University of Tokyo supervised by Prof. <a href="https://scholar.google.com/citations?user=4gH3sxsAAAAJ&hl=zh-CN">Yinqiang
                      ZHENG</a>.
                    <br>
                    <br>
                    My current research interest includes Visual-Language Model (VLM) and Adversarial Attack.
                  </p>
                  </p>
                  <p style="text-align:center">
                    <a href="mailto:ran-weihang@g.ecc.u-tokyo.ac.jp">Email</a> &nbsp/&nbsp
                    <a href="https://github.com/SilverRAN">Github</a> &nbsp/&nbsp
                    <a href="file/CV_Shuwei Shi.pdf">CV</a> &nbsp/&nbsp
                    <a href="https://scholar.google.com/citations?user=ofa8fFoAAAAJ&hl=zh-CN">Google Scholar</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="images/shuweishi.jpg"><img style="width:50%;max-width:50%" alt="profile photo"
                      src="images/shuweishi.jpg" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <h2>Education Background</h2>
            <tr style="padding:0px">
              <td style="padding:2.5%;vertical-align:left">
                <p>
		  <div class="container">
		    <div class="left-align"><strong>The University of Tokyo</strong></div>
		    <div class="right-align">Oct.2023 - Sep.2026 (Expected)</div>
		  </div>
                </p>
		<p>„Éª1st year Doctoral student in Mechano-Informatics, the Graduate School of Information Science and Technology</p>
		<p>„ÉªSupervisor: Prof. <a href="https://scholar.google.co.jp/citations?user=JD-5DKcAAAAJ&hl=ja">Yinqiang ZHENG</a></p>
		<p>„ÉªResearch Theme: Adversarial attack, Visual-Language Models</p>
                <p>
                  <div class="container">
		    <div class="left-align"><strong>The University of Tokyo</strong></div>
		    <div class="right-align">Oct.2021 - Sep.2023</div>
		  </div>
                </p>
                <p>„ÉªM.E. in Socio-Cultural Environmental Study, the Graduate School of Frontier Sciences</p>
		<p>
		  „ÉªSupervisor: Prof. <a href="https://scholar.google.com/citations?user=0UjOE4IAAAAJ&hl=en">Ryosuke SHIBASAKI</a> 
		  and Prof. <a href="https://scholar.google.com/citations?user=_qCSLpMAAAAJ&hl=zh-CN">Xuan SONG</a>
		</p>
		<p>„ÉªThesis: Object Detection and Vectorization System for Urban Monitoring</p>
		<p>
                  <div class="container">
		    <div class="left-align"><strong>Wuhan University</strong></div>
		    <div class="right-align">Sep.2015 - Jun.2020</div>
		  </div>
                </p>
                <p>„ÉªB.Arch. in Architecture, School of Urban Design</p>
		<p>„ÉªGPA: 3.3/4.0</p>
              </td>
            </tr>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px;width:100%;vertical-align:middle;padding-top: 60px">
                  <heading>Publications</heading>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr onmouseout="nips22_stop()" onmouseover="nips22_start()">
                <td style="padding:0px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='c5_image' style="padding-top: 30px;">
                      <img src='images/psrt.jpg' width="180">
                    </div>
                    <script type="text/javascript">
                      function dualfont_start() {
                        document.getElementById('dualfont_image').style.opacity = "1";
                      }

                      function dualfont_stop() {
                        document.getElementById('dualfont_image').style.opacity = "0";
                      }
                      dualfont_stop()
                    </script>
                </td>
                <td style="padding:0px;width:75%;vertical-align:middle">
                  <a href="https://openaccess.thecvf.com/content/CVPR2023W/PCV/html/Ran_Few-Shot_Depth_Completion_Using_Denoising_Diffusion_Probabilistic_Model_CVPRW_2023_paper.html">
                    <papertitle>Few-Shot Depth Completion Using Denoising Diffusion Probabilistic Model.</papertitle>
                  </a>
                  <br>
                  <strong>Weihang Ran</strong>, Wei Yuan, Ryosuke Shibasaki.
                  <br>
                  <em>CVPR Workshop 2023
                    <br>
                    <a href="https://openaccess.thecvf.com/content/CVPR2023W/PCV/html/Ran_Few-Shot_Depth_Completion_Using_Denoising_Diffusion_Probabilistic_Model_CVPRW_2023_paper.html">paper</a>
                    <p></p>
                </td>
              </tr>


              <tr onmouseout="workshop1_stop()" onmouseover="workshop1_start()">
                <td style="padding:0px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='c5_image' style="padding-top: 30px;">
                      <img src='images/AHIQ.png' width="180">
                    </div>
                    <script type="text/javascript">
                      function dualfont_start() {
                        document.getElementById('dualfont_image').style.opacity = "1";
                      }

                      function dualfont_stop() {
                        document.getElementById('dualfont_image').style.opacity = "0";
                      }
                      dualfont_stop()
                    </script>
                </td>
                <td style="padding:0px;width:75%;vertical-align:middle">
                  <a
                    href="https://ieeexplore.ieee.org/abstract/document/10265007">
                    <papertitle>Multiconstraint Transformer-Based Automatic Building Extraction 
		    From High-Resolution Remote Sensing Images.</papertitle>
                  </a>
                  <br>
                  Wei Yuan*, <strong>Weihang Ran*</strong>, Xiaodan Shi,
                  Ryosuke Shibasaki.
                  <br>
                  <em>IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing
                    <br>
                    <a
                      href="https://ieeexplore.ieee.org/abstract/document/10265007">paper</a>
                    <p></p>
                </td>
              </tr>

              <tr onmouseout="workshop2_stop()" onmouseover="workshop2_start()">
                <td style="padding:0px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='c5_image' style="padding-top: 30px;">
                      <img src='images/MANIQA.png' width="180">
                    </div>
                    <script type="text/javascript">
                      function dualfont_start() {
                        document.getElementById('dualfont_image').style.opacity = "1";
                      }

                      function dualfont_stop() {
                        document.getElementById('dualfont_image').style.opacity = "0";
                      }
                      dualfont_stop()
                    </script>
                </td>
                <td style="padding:0px;width:75%;vertical-align:middle">
                  <a href="https://ieeexplore.ieee.org/abstract/document/10282867">
                    <papertitle>Hybrid Feature Embedding for Automatic Building Outline 
		    Extraction.</papertitle>
                  </a>
                  <br>
                  <strong>Weihang Ran*</strong>, Wei Yuan, Xiaodan Shi, Zipei Fan,
                  Ryosuke Shibasaki.
                  <br>
                  <em>IEEE International Geoscience and Remote Sensing Symposium (IGARSS) 2023
                    <br>
                    <a
                      href="https://ieeexplore.ieee.org/abstract/document/10282867">paper</a>
                    <p></p>
                </td>
              </tr>

              <tr onmouseout="workshop3_stop()" onmouseover="workshop3_start()">
                <td style="padding:0px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='c5_image' style="padding-top: 30px;">
                      <img src='images/AttentionProbe.png' width="180">
                    </div>
                    <script type="text/javascript">
                      function dualfont_start() {
                        document.getElementById('dualfont_image').style.opacity = "1";
                      }

                      function dualfont_stop() {
                        document.getElementById('dualfont_image').style.opacity = "0";
                      }
                      dualfont_stop()
                    </script>
                </td>
                <td style="padding:0px;width:75%;vertical-align:middle">
                  <a href="https://ieeexplore.ieee.org/abstract/document/10283247">
                    <papertitle>Graph Encoding based Hybrid Vision Transformer for Automatic Road Network Extraction.
                    </papertitle>
                  </a>
                  <br>
                  Wei Yuan, <strong>Weihang Ran</strong>, Xiaodan Shi, Zipei Fan, Yang Cai and Ryosuke Shibasaki.
                  <br>
                  <em>IEEE International Geoscience and Remote Sensing Symposium (IGARSS) 2023
                    <br>
                    <a href="https://ieeexplore.ieee.org/abstract/document/10283247">paper</a>
                    <p></p>
                </td>
              </tr>


              <tr onmouseout="workshop3_stop()" onmouseover="workshop3_start()">
                <td style="padding:0px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='c5_image' style="padding-top: 30px;">
                      <!-- <img src='images/longyoutubevis.png' width="180"></div> -->
                      <img src='images/RADN.png' width="180">
                    </div>
                    <script type="text/javascript">
                      function dualfont_start() {
                        document.getElementById('dualfont_image').style.opacity = "1";
                      }

                      function dualfont_stop() {
                        document.getElementById('dualfont_image').style.opacity = "0";
                      }
                      dualfont_stop()
                    </script>
                </td>
                <td style="padding:0px;width:75%;vertical-align:middle">
                  <a
                    href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/papers/Shi_Region-Adaptive_Deformable_Network_for_Image_Quality_Assessment_CVPRW_2021_paper.pdf">
                    <papertitle>Region-Adaptive Deformable Network for Image Quality Assessment.
                    </papertitle>
                  </a>
                  <br>
                  <strong>Shuwei Shi*</strong>, Qingyan Bai*, Mingdeng Cao, Weihao Xia, Jiahao Wang, Yifan Chen, Yujiu
                  Yang.
                  <br>
                  <em>CVPR Workshop 2021
                    <br>
                    <a
                      href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/papers/Shi_Region-Adaptive_Deformable_Network_for_Image_Quality_Assessment_CVPRW_2021_paper.pdf">paper</a>
                    /
                    <a href="https://github.com/IIGROUP/RADN">code</a>
                    <p></p>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <h2>Peer Reviewer</h2>
            <tr style="padding:0px">
              <td style="padding:2.5%;vertical-align:left">
                <p>
                  Conference: AAAI
                </p>
                <p>
                  Jounal: IJCV, TCSVT
                </p>
              </td>
            </tr>
          </table>




          <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Manuscripts</heading>
            </td>
          </tr>
        </tbody></table>
         <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
	 <tr onmouseout="iros22_stop()" onmouseover="iros22_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='c5_image'>
                  <img src='images/avis.png' width="180"></div>
                <img src='images/avis.png' width="180">
              </div>
              <script type="text/javascript">
                function dualfont_start() {
                  document.getElementById('dualfont_image').style.opacity = "1";
                }

                function dualfont_stop() {
                  document.getElementById('dualfont_image').style.opacity = "0";
                }
                dualfont_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2207.05580.pdf">
                <papertitle>Online Video Instance Segmentation via Robust Context Fusion.</papertitle>
              </a>
              <br>
              <a href="https://lxa9867.github.io/">Xiang Li</a>, <a href="https://www.microsoft.com/en-us/research/people/jinglwa/research/">Jinglu Wang</a>, <strong>Xiaohao Xu</strong>, <a href="https://scholar.google.com.au/citations?hl=ca&user=IWcGY98AAAAJ&view_op=list_works">Bhiksha Raj</a>, <a href="https://scholar.google.com/citations?user=djk5l-4AAAAJ&hl=en">Yan Lu</a>.
              <br>
              Under review of <em>IEEE Transactions on Image Processing (TIP)</em>.
	      <br>
		    <a href="https://arxiv.org/pdf/2207.05580.pdf">paper</a>
              <p></p>
              <p>We design a robust context fusion module for modeling compact and effective spatio-temporal correlations for online VIS. Meanwhile, a matching-free and supervision-free instance identity tracking method, and its corresponding mathematical explanation are proposed.</p>
            </td>
          </tr>
          <tr onmouseout="iros22_stop()" onmouseover="iros22_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='c5_image'>
                  <img src='images/rrvos.jpg' width="180"></div>
                <img src='images/rrvos.jpg' width="180">
              </div>
              <script type="text/javascript">
                function dualfont_start() {
                  document.getElementById('dualfont_image').style.opacity = "1";
                }

                function dualfont_stop() {
                  document.getElementById('dualfont_image').style.opacity = "0";
                }
                dualfont_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2207.10915">
                <papertitle>Robust Referring Video Object Segmentation via Relational Multimodal Cycle Consistency.</papertitle>
              </a>
              <br>
              <a href="https://lxa9867.github.io/">Xiang Li</a>, <a href="https://www.microsoft.com/en-us/research/people/jinglwa/research/">Jinglu Wang</a>, <strong>Xiaohao Xu</strong>, <a href="https://scholar.google.com/citations?hl=en&user=hEPx3rwAAAAJ&view_op=list_works&sortby=pubdate">Xiao Li</a>,<a href="https://scholar.google.com/citations?user=djk5l-4AAAAJ&hl=en">Yan Lu</a>, <a href="https://scholar.google.com.au/citations?hl=ca&user=IWcGY98AAAAJ&view_op=list_works">Bhiksha Raj</a>.
              <br>
              Under review of <em>IEEE / CVF Computer Vision and Pattern Recognition Conference (CVPR)</em>, 2023.
	      <br>
		    <a href="https://arxiv.org/abs/2207.10915">paper</a>
		    /
		    <a href="https://www.youtube.com/watch?v=xzL8olvgqRY">demo</a>
		    /
		    <a href="https://lxa9867.github.io/works/rrvos/index.html">website</a>
              <p></p>
              <p>We are the first to address the severe false-alarm problem faced by R-VOS methods and study how to resolve that.</p>
            </td>
          </tr>
		   <tr onmouseout="iros22_stop()" onmouseover="iros22_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='c5_image'>
                  <img src='images/cs.jpeg' width="140"></div>
                <img src='images/cs.jpeg' width="140">
              </div>
              <script type="text/javascript">
                function dualfont_start() {
                  document.getElementById('dualfont_image').style.opacity = "1";
                }

                function dualfont_stop() {
                  document.getElementById('dualfont_image').style.opacity = "0";
                }
                dualfont_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="">
                <papertitle>Open-set Supervised Anomaly Localization via Union Discrepancy Learners.</papertitle>
              </a>
              <br>
              <a href="https://www.researchgate.net/profile/Yunkang-Cao">Yunkang Cao</a>, <strong>Xiaohao Xu</strong>,<a href="https://scholar.google.ca/citations?user=FuSHsx4AAAAJ&hl=en">Weiming Shen</a>.
              <br>
              Under review of <em>IEEE Transactions on Cybernetics (Tcyb)</em>.
              <p></p>
            </td>
          </tr>
	 <tr onmouseout="iros22_stop()" onmouseover="iros22_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='c5_image'>
                  <img src='images/cs.jpeg' width="140"></div>
                <img src='images/cs.jpeg' width="140">
              </div>
              <script type="text/javascript">
                function dualfont_start() {
                  document.getElementById('dualfont_image').style.opacity = "1";
                }

                function dualfont_stop() {
                  document.getElementById('dualfont_image').style.opacity = "0";
                }
                dualfont_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="">
                <papertitle>Collaborative Discrepancy Optimization for Reliable Image Anomaly Detection.</papertitle>
              </a>
              <br>
              <a href="https://www.researchgate.net/profile/Yunkang-Cao">Yunkang Cao</a>, <strong>Xiaohao Xu</strong>,Zhaoge Liu, <a href="https://scholar.google.ca/citations?user=FuSHsx4AAAAJ&hl=en">Weiming Shen</a>.
              <br>
              Under review of <em>IEEE Transactions on Industrial Informatics (TII)</em>.
              <p></p>
            </td>
          </tr>
	</tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Patents</heading>
            </td>
          </tr>
        </tbody></table>
	 <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="aaai22_stop()" onmouseover="aaai22_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='c5_image'>
                  <img src='images/patent_exoskeleton.jpg' width="140"></div>
                <img src='images/patent_exoskeleton.jpg' width="140">
              </div>
              <script type="text/javascript">
                function dualfont_start() {
                  document.getElementById('dualfont_image').style.opacity = "1";
                }

                function dualfont_stop() {
                  document.getElementById('dualfont_image').style.opacity = "0";
                }
                dualfont_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://patents.google.com/patent/CN113305805A/en?q=(Passive+double-frame+bionic+exoskeleton+back+device)&oq=(Passive+double-frame+bionic+exoskeleton+back+device)">
                <papertitle>Passive Double-frame Bionic Exoskeleton Back Device.</papertitle></a>
		     <br>
		      ZL202110402575.6, <strong>Granted</strong> Oct 2022.
		    <br>
		    Collaborated with my friends: R. Zhang, Z. Du, H. Zhang, Z. Hong; Advised by Prof. B. Han
              </a>
            </td>
          </tr>
	  <tr onmouseout="aaai22_stop()" onmouseover="aaai22_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='c5_image'>
                  <img src='images/patent_signal.jpg' width="140"></div>
                <img src='images/patent_signal.jpg' width="140">
              </div>
              <script type="text/javascript">
                function dualfont_start() {
                  document.getElementById('dualfont_image').style.opacity = "1";
                }

                function dualfont_stop() {
                  document.getElementById('dualfont_image').style.opacity = "0";
                }
                dualfont_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://patents.google.com/patent/CN111850918B/en?q=Foldable+automatic+sock+washing+and+airing+all-in-one+machine&oq=Foldable+automatic+sock+washing+and+airing+all-in-one+machine">
                <papertitle>Distributed Arm Force Sensing Signal Acquisition Device.</papertitle></a>
		      <br>
		      ZL202110871934.2, <strong>Granted</strong> Feb 2022.
		    		     <br>
		    Collaborated with my friends: H. Zhang, Z. Hong, R. Zhang, Z. Du; Advised by Prof. B. Han
              </a>
            </td>
          </tr>
	  <tr onmouseout="aaai22_stop()" onmouseover="aaai22_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='c5_image'>
                  <img src='images/patent_sock.jpg' width="140"></div>
                <img src='images/patent_sock.jpg' width="140">
              </div>
              <script type="text/javascript">
                function dualfont_start() {
                  document.getElementById('dualfont_image').style.opacity = "1";
                }

                function dualfont_stop() {
                  document.getElementById('dualfont_image').style.opacity = "0";
                }
                dualfont_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
             <a href="https://patents.google.com/patent/CN111850918B/en?q=Foldable+automatic+sock+washing+and+airing+all-in-one+machine&oq=Foldable+automatic+sock+washing+and+airing+all-in-one+machine">
                <papertitle>Foldable Automatic Sock Washing and Airing All-in-one Machine.</papertitle></a>
		      <br>
		      ZL202010621100.1, <strong>Granted</strong> July 2021.
		     <br>
		    Collaborated with my friends: H. Zhang, T. Zheng, J. Song, X. Dou; Advised by Prof. B. Han
              </a>
            </td>
          </tr>
	  <tr onmouseout="aaai22_stop()" onmouseover="aaai22_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='c5_image'>
                  <img src='images/patent_rubik.jpg' width="140"></div>
                <img src='images/patent_rubik.jpg' width="140">
              </div>
              <script type="text/javascript">
                function dualfont_start() {
                  document.getElementById('dualfont_image').style.opacity = "1";
                }

                function dualfont_stop() {
                  document.getElementById('dualfont_image').style.opacity = "0";
                }
                dualfont_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://patents.google.com/patent/CN111037581A/en?q=Electromagnetic+dual-arm+magic+cube+solving+robot+and+control&oq=Electromagnetic+dual-arm+magic+cube+solving+robot+and+control">
                <papertitle>Electromagnetic Dual-arm Magic Cube Solving Robot.</papertitle></a>
		      <br>
		      CN201911402703.6A, <strong>Publicized</strong> April 2020.
		    <br>
		    Collaborated with my friends: F. Zuo, J. Chen, and H. Zhang; Advised by Prof. B. Han
              </a>
            </td>
          </tr>

        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
           <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Technical Services</heading>
              <p>
                 <strong>Reviewer/Program Committee Member</strong>:
		      <br>
		      The IEEE / CVF Computer Vision and Pattern Recognition Conference (CVPR) 2022-2023,
		      <br>
		      European Conference on Computer Vision (ECCV) 2022,
		      <br>
		      ACM International Conference on Multimedia (ACM Multimedia) 2022,
		      <br>
		      AAAI Conference on Artificial Intelligence (AAAI) 2023
	  </p>
            </td>
          </tr>
	    </tbody></table>
		<table width="100%" align="center" border="0" cellpadding="20"><tbody>
		   <tr>
		    <td style="padding:20px;width:100%;vertical-align:middle;text-align:justify">
		      <heading>Selected Honors</heading>
		      <p>
			 <strong>Star of Tomorrow Award</strong> from Microsoft Research Asia (Top 10% Interns at MSRA)   	(2022)
			  <br>
			  <strong>Outstanding Undergraduate Thesis</strong> Award at HUST (Top 0.4%)	                        (2022)
			 <br>
			  <strong>Outstanding Graduates Award</strong> at HUST	                                                (2022)
			 <br>
			  <strong>Star of Scientific and Technological Innovation</strong> Award at HUST (Top 1%)        	(2020)
			 <br>
			 <strong>Hui Chuan Technology Scholarship</strong> at HUST (2 undergraduates yearly at college) 	        (2020)
			 <br>
			 <strong>Science and Technology Innovation Scholarship</strong> at HUST                             (2020-2022)
			 <br>
			 <strong>Outstanding Undergraduate in Terms of Academic Performance</strong> Award at HUST (Top 1%)	(2019)
			 </p>
		    </td>
		  </tr>

	 </tbody></table>
		<table width="100%" align="center" border="0" cellpadding="20"><tbody>
		   <tr>
		    <td style="padding:20px;width:100%;vertical-align:middle;text-align:justify">
		      <heading>Selected Competition Awards</heading>
		      <p>
			 <strong>National First Prize</strong> of Innovation Track at the Sixth National Youth Artificial Intelligence Innovation and Entrepreneurship Conference, <em>Chinese Association for Artificial Intelligence</em>		(2021)
			  <br>
			  <strong>National First Prize</strong> of China Collegiate Computing Contest, <em>Ministry of Education</em>	(2020)
			 <br>
			  <strong>Gold Medal</strong> of Citation Intent Recognition Task in WSDM Cup Algorithm Challenge, <em>the 13th ACM International Conference on Web Search and Data Mining</em>		(2020)
			 <br>
			  <strong>National First Prize</strong> of Huawei Cloud Cup AI Application Innovation Competition, <em>Huawei Corp.</em> 		(2020)
			 <br>
			 <strong>National Champion</strong> of Innovative Thinking and Frontier Design of AI Track in DeeCamp Global AI Leader Training Program, <em>Sinovation Ventures Corp.</em>		(2020)
			 <br>
			 <strong>National First Prize</strong> of Rubik's Cube Robot Track in National University Intelligent Robot Competition, <em>Ministry of Education</em>	(2019)
			 <br>
			 <strong>National Second Prize</strong> of China Intelligent Robot Combat Competition, <em>Ministry of Education</em>		(2019)
			 <br>
			 <strong>National Second Runner-up Prize</strong> of DiggSci Data Mining Contest, <em>Microsoft Corp.</em>		(2019)
			 <br>
			<strong>Honorable Mention Award</strong> of Interdisciplinary Contest in Modeling (ICM), <em>COMAP</em>		(2019)
			 <br>
			<strong>Top Four</strong> of Central Division of RoboMaster in National Undergraduate Robot Competition, <em>DJI Corp.</em>		(2019)
			 </p>
		    </td>
		  </tr>

	    </tbody></table>
			<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
			    <tr>
			    <td style="padding:20px;width:100%;vertical-align:middle">
			      <heading>Self-made Robots</heading>
			    </td>
			  </tr>
			</tbody></table>

                 <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                         <td style="padding:20px;width:50%;vertical-align:middle">
			      <iframe
				width="280"
				height="150"
				src="https://www.youtube.com/embed/TL_V4A_qG98?autoplay=0&mute=1"
				title="YouTube video player"
				frameborder="0"
				allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
				allowfullscreen
			      ></iframe>
			  </td>
			<td style="padding:20px;width:50%;vertical-align:middle">
				<papertitle>Rubik's Cube Solver.</papertitle></a>
			            <br>
				    Collaborated with my friends: F. Zuo, J. Chen, H. Zhang
                                     <br>
                                     The average time to restore a random Rubik's cube is ~5.42s.
		        </td>
	        </tbody></table>

                <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                          <td style="padding:20px;width:50%;vertical-align:middle">
			      <iframe
				width="280"
				height="150"
				src="https://www.youtube.com/embed/WcL-70J6f_4?autoplay=0&mute=1"
				title="YouTube video player"
				frameborder="0"
				allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
				allowfullscreen
			      ></iframe>
			  </td>

			<td style="padding:20px;width:50%;vertical-align:middle">
				<papertitle>Nail Painting Machine.</papertitle></a>
			             <br>
				    Collaborated with my classmates: J. Luo, C. Cao.
                                     <br>

			    </td>
	        </tbody></table>
	       <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                      <td style="padding:20px;width:50%;vertical-align:middle">
			      <iframe
				width="280"
				height="150"
				src="https://www.youtube.com/embed/knQp0Kfn134?autoplay=0&mute=1"
				title="YouTube video player"
				frameborder="0"
				allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
				allowfullscreen
			      ></iframe>
			  </td>
			<td style="padding:20px;width:50%;vertical-align:middle">
				<papertitle>Four-legged Dog.</papertitle></a>
		                     <br>
				    Collaborated with my friends at Robocon Robot Team.
                                     <br>

			    </td>
                            <br>
                </tbody></table>
                   <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
		          <td style="padding:20px;width:50%;vertical-align:middle">
			      <iframe
				width="280"
				height="150"
				src="https://www.youtube.com/embed/DOImbTi7o8Q?autoplay=0&mute=1"
				title="YouTube video player"
				frameborder="0"
				allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
				allowfullscreen
			      ></iframe>
			  </td>
			<td style="padding:20px;width:50%;vertical-align:middle">
				<papertitle>Vision-based Self-driving Mecanum-wheeled Robot.</papertitle></a>
			           <br>
				    Collaborated with my friend: Z. Zeng.
                                     <br>

			</td>
                          <br>
	        </tbody></table>
                   <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
		          <td style="padding:20px;width:50%;vertical-align:middle">
			      <iframe
				width="280"
				height="150"
				src="https://www.youtube.com/embed/5Y7UqpMtJCU?autoplay=0&mute=1"
				title="YouTube video player"
				frameborder="0"
				allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
				allowfullscreen
			      ></iframe>
			  </td>
			<td style="padding:20px;width:50%;vertical-align:middle">
				<papertitle>Self-aiming-and-shooting Robot.</papertitle></a>
			           <br>
				    Collaborated with my friends at MSE-STAR Robot Team.
                                     <br>

			</td>
                          <br>
	        </tbody></table>
                   <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
		          <td style="padding:20px;width:50%;vertical-align:middle">
			      <iframe
				width="280"
				height="150"
				src="https://www.youtube.com/embed/6tyiwAx-0k0?autoplay=0&mute=1"
				title="YouTube video player"
				frameborder="0"
				allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
				allowfullscreen
			      ></iframe>
			  </td>
			<td style="padding:20px;width:50%;vertical-align:middle">
				<papertitle>Intelligent Line Patrol Car.</papertitle></a>
			           <br>
				    Collaborated with my friends: Z. Zeng, Y. Yang.
                                     <br>

			</td>
                          <br>
	        </tbody></table>

      </tbody></table> -->



          <!-- <p align="center"><font color="#999999"> Design and source code from <a style="font-size:small;" href="https://leonidk.com/">Leonid Keselman </a> and <a style="font-size:small;" href="https://jonbarron.info">Jon Barron</a></font></p>
<p align="center"><font color="#999999">Last update: Oct. 15, 2022</font></p> -->
</body>

</html>
